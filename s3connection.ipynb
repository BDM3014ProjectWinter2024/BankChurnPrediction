{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "# Download the credentials in teams and save in your local machine, update the path as needed\n",
    "file_path = 'C:/churn/bucketcredentials.csv'\n",
    "credentials_df = pd.read_csv(file_path)\n",
    "\n",
    "aws_access_key_id = credentials_df['aws_access_key_id'].iloc[0]\n",
    "aws_secret_access_key = credentials_df['aws_secret_access_key'].iloc[0]\n",
    "bucket_name = credentials_df['bucket_name'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 client\n",
    "s3_client = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set param\n",
    "# for testing purposes you can change the path so you will not overwrite others output file\n",
    "env = \"test\" #  dev, test, staging, prod \n",
    "model = \"model1\" # model1, model2, model3\n",
    "mainsource = \"SourceDataSet/bank_data_train.csv\"\n",
    "envraw = f'{env}/raw/bank_data_train.csv'\n",
    "\n",
    "#for pre processing and feature engineering we only have one source \n",
    "sourcedata = \"raw\" \n",
    "targetdata = \"processed\"\n",
    "sourcefoldername = f'{env}/{sourcedata}'\n",
    "targetfoldername = f'{env}/{targetdata}'\n",
    "sourcefilename = \"bank_data_train.csv\"\n",
    "targetfilename = \"bank_data_test.csv\"\n",
    "\n",
    "# for modeling may vary on environment, and user\n",
    "# sourcedata = \"processed\" \n",
    "# targetdata = \"final\"\n",
    "# sourcefoldername = f'{env}/{sourcedata}'\n",
    "# targetfoldername = f'{env}/{targetdata}/{model}'\n",
    "# sourcefilename = \"bank_data_test.csv\"\n",
    "# targetfilename = \"bank_data.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_and_transfer_file(bucket_name, source_key, raw_destination_key):\n",
    "    try:\n",
    "        # Check if the file exists in the destination location\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=raw_destination_key)\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print('test')\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            s3_client.copy_object(Bucket=bucket_name, CopySource=f\"{bucket_name}/{source_key}\", Key=raw_destination_key)\n",
    "        else:\n",
    "            print(\"An error occurred:\", e)\n",
    "# \n",
    "\n",
    "def check_file_exists(bucket_name, file_key):\n",
    "    try:\n",
    "        # Check if the file exists\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=file_key)\n",
    "        return True\n",
    "        #print(f\"File '{file_key}' exists.\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            return False\n",
    "        else:\n",
    "            return False\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SourceDataSet in env\n",
    "check_and_transfer_file(bucket_name, mainsource, envraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file from S3 into a DataFrame\n",
    "input_file_key = f'{sourcefoldername}/{sourcefilename}'\n",
    "output_file_key = f'{targetfoldername}/{targetfilename}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if raw data exists\n",
    "file_exists = check_file_exists(bucket_name,input_file_key)\n",
    "if file_exists:\n",
    "    obj = s3_client.get_object(Bucket=bucket_name, Key=input_file_key)\n",
    "    df = pd.read_csv(obj['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first two rows of the DataFrame\n",
    "#df_head = df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a CSV string\n",
    "csv_buffer = StringIO()\n",
    "df_head.to_csv(csv_buffer, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'XM39CTEMNSTS75BQ',\n",
       "  'HostId': 'BNN+HlCh8KuhPrk3BEoN7gyyxdohGUGYseCsUff5pkPV7DAf+AZW2GR5Nil9JAJNSrjfkLeDMpA=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'BNN+HlCh8KuhPrk3BEoN7gyyxdohGUGYseCsUff5pkPV7DAf+AZW2GR5Nil9JAJNSrjfkLeDMpA=',\n",
       "   'x-amz-request-id': 'XM39CTEMNSTS75BQ',\n",
       "   'date': 'Tue, 19 Mar 2024 23:32:58 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"c3ece34322f24c713d7483a700cb53fd\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"c3ece34322f24c713d7483a700cb53fd\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Upload the new CSV to the desired folder in the S3 bucket\n",
    "s3_client.put_object(Bucket=bucket_name, Key=output_file_key, Body=csv_buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
