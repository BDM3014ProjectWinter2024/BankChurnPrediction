{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below if you want to run this file only\n",
    "%run main.ipynb\n",
    "#%run data_cleaning.ipynb\n",
    "#%run data_visualization.ipynb\n",
    "#%run feature_engineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV From FEATURE ENGINEERING data source file from S3 into a DataFrame\n",
    "# Use the methods from the S3Utils class\n",
    "if s3_utils.check_file_exists(output_file_key_data_feature_engineering):\n",
    "    dataset = s3_utils.read_csv_from_s3(output_file_key_data_feature_engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                0\n",
       "amount_rub_clo_prc            38323\n",
       "amount_rub_sup_prc            38323\n",
       "rest_dynamic_save_3m              0\n",
       "rest_avg_cur                      0\n",
       "amount_rub_nas_prc            38323\n",
       "amount_rub_atm_prc            38323\n",
       "rest_dynamic_fdep_3m              0\n",
       "rest_avg_paym                     0\n",
       "ldeal_grace_days_pct_med          0\n",
       "rest_dynamic_cur_3m               0\n",
       "rest_dynamic_paym_3m              0\n",
       "rest_dynamic_il_3m                0\n",
       "rest_dynamic_cc_3m                0\n",
       "pack_encoded                      0\n",
       "number_products                   0\n",
       "new_age_category_numeric          0\n",
       "new_setup_tenor                   0\n",
       "total_turnover_category           0\n",
       "total_turnover_1m_category        0\n",
       "total_turnover_3m_category        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check for missing values\n",
    "X.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "X = pd.DataFrame(X_imputed, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355190, 21)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'dev/final/model_c/bank_data_test.csv' successfully written to bucket 'introtoaiwinter24'.\n"
     ]
    }
   ],
   "source": [
    "# # This Write the bank_data_test data to S3, Just to check the test data that will be used\n",
    "# csv_X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "# s3_utils.write_csv_to_s3(output_file_key_data_model_three_test, csv_X_test_scaled)\n",
    "# print(f\"File '{output_file_key_data_model_three_test}' successfully written to bucket '{s3_utils.bucket_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE oversampling\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=5)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM model using LinearSVC\n",
    "linearsvc_model = LinearSVC(class_weight='balanced', dual=False, random_state=42)\n",
    "\n",
    "linearsvc_param_distributions = {\n",
    "    'C': [0.1, 1, 10, 100],  # [0.1, 1, 10, 100] Regularization parameter\n",
    "    'loss': ['squared_hinge'],  # Specifies the loss function\n",
    "    'max_iter': [1000, 5000, 10000]  # Maximum number of iterations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    linearsvc_model,\n",
    "    param_distributions=linearsvc_param_distributions,\n",
    "    n_iter=10,                         # Number of parameter settings sampled\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "random_search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fitting, you can get the best hyperparameters and the corresponding score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best roc_auc : {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model using the best hyperparameters on the resampled training data\n",
    "linearsvc_model.set_params(**best_params)\n",
    "linearsvc_model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the retrained model on the test data\n",
    "y_pred = linearsvc_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the scores\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve and AUC-ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUC-ROC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Dashed diagonal\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC (Receiver Operating Characteristic) curve provided is a graphical representation that shows the diagnostic ability of a binary classifier system as its discrimination threshold is varied. For the bank churn prediction dataset, the ROC curve and the AUC (Area Under the Curve) score are used to evaluate the performance of the classification model. Hereâ€™s what this specific ROC curve and the AUC-ROC value tell's the model:\n",
    "\n",
    "1. **ROC Curve Shape**: The blue line represents the performance of the classification model. A perfect classifier would have a line going from the bottom left to the top left and then across to the top right (a right angle). The curve is above the dashed line (which represents random chance), indicating that the model has learned something meaningful.\n",
    "\n",
    "2. **AUC-ROC Value**: The AUC-ROC value is 0.62, which is a measure of the area under the ROC curve. The value ranges from 0.5 (no discrimination ability) to 1.0 (perfect discrimination ability). A score of 0.62 suggests that the model is able to discriminate between the positive class (customers who churn) and the negative class (customers who don't churn) better than random chance, but it's not a strong model. Usually, an AUC-ROC score above 0.7 is considered acceptable, above 0.8 is considered excellent, and above 0.9 is outstanding.\n",
    "\n",
    "Based on this chart, the model has room for improvement. To enhance model performance:\n",
    "\n",
    "- Gathering more features that could help in predicting churn.\n",
    "- Trying different preprocessing techniques.\n",
    "- Experimenting with different models and algorithms.\n",
    "- Tuning hyperparameters more finely.\n",
    "- Utilizing more advanced techniques like ensemble methods.\n",
    "\n",
    "will look for other metrics such as precision, recall, and F1 score, especially because the dataset is imbalanced. These metrics can provide additional insights into the model's performance, particularly in how it handles the minority class (churned customers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install shap lime joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a .pkl file\n",
    "joblib.dump(linearsvc_model, 'model.pkl')\n",
    "\n",
    "model_file_path='model.pkl'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model.pkl file to S3\n",
    "s3_utils.upload_file(output_file_key_data_svm_model_pkl, model_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create the directory\n",
    "model_dir = 'model_dir'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Move the model.pkl file into the directory\n",
    "shutil.move('model.pkl', os.path.join(model_dir, 'model.pkl'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Create a tar.gz archive of the model_dir directory\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    tar.add(model_dir, arcname=os.path.basename(model_dir))\n",
    "\n",
    "# Upload the model.tar.gz file to S3\n",
    "model_s3_tar = output_file_key_data_svm_model_tar  # Adjust the path as needed\n",
    "s3_utils.upload_file(model_s3_tar, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "# Specify the inference image\n",
    "image_uri = sagemaker.image_uris.retrieve('sklearn', sagemaker.Session().boto_region_name, version='0.23-1')\n",
    "\n",
    "# Create a SageMaker model\n",
    "model = SKLearnModel(\n",
    "    model_data=f's3://{bucket_name}/{model_key}',\n",
    "    image_uri=image_uri,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    entry_point='inference.py'  # Script for model loading and inference\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from lime import lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "print(feature_names)\n",
    "# SHAP Analysis\n",
    "# Create a SHAP explainer\n",
    "shap_explainer = shap.Explainer(linearsvc_model, X_train_scaled)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = shap_explainer(X_test_scaled)\n",
    "\n",
    "# Manually set the feature names in the SHAP values object\n",
    "shap_values.feature_names = feature_names\n",
    "\n",
    "# Plot the SHAP values for the first instance in the test set\n",
    "shap_plot = shap.plots.waterfall(shap_values[0])\n",
    "plt.savefig('shap_plot.png', bbox_inches='tight')\n",
    "plt.clf()  # Clear the figure after saving\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
